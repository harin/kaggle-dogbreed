{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on content from\n",
    "https://towardsdatascience.com/image-classification-python-keras-tutorial-kaggle-challenge-45a6332a58b8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers. normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_dict = {} # id: breed\n",
    "f = open(\"labels.csv\", \"r\")\n",
    "fileContents = f.read()\n",
    "fileContents = fileContents.split('\\n')\n",
    "for i in range(len(fileContents) - 1):\n",
    "    fileContents[i] = fileContents[i].split(',')\n",
    "    naming_dict[fileContents[i][0]] = fileContents[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = naming_dict.values()\n",
    "breed_set = set(breeds)\n",
    "counting_dict = {}\n",
    "for i in breed_set:\n",
    "    counting_dict[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(name):\n",
    "    if not os.path.isdir(name):\n",
    "        os.mkdir(name)\n",
    "create_dir('labeled_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in os.listdir('./train'):\n",
    "    imgName = img.split('.')[0]\n",
    "    label = naming_dict[str(imgName)]\n",
    "    counting_dict[label] += 1\n",
    "    path = os.path.join('./train', img)\n",
    "    saveName = f\"./labeled_train/{label}-{str(counting_dict[label])}.jpg\"\n",
    "    image_data = np.array(Image.open(path))\n",
    "    imageio.imwrite(saveName, image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(name):\n",
    "    word_label = name.split('-')[0]\n",
    "    if word_label == 'golden_retriever' : return np.array([1, 0])\n",
    "    if word_label == 'shetland_sheepdog': return np.array([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_stats(DIR):\n",
    "    heights = []\n",
    "    widths = []\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        data = np.array(Image.open(path))\n",
    "        heights.append(data.shape[0])\n",
    "        widths.append(data.shape[1])\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    \n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height: 386.74721189591077\n",
      "Max Height: 2562\n",
      "Min Height: 102\n",
      "\n",
      "\n",
      "Average Width: 443.33153981608297\n",
      "Max Width: 3264\n",
      "Min Width: 97\n"
     ]
    }
   ],
   "source": [
    "get_size_stats('labeled_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(DIR='labeled_train'):\n",
    "    train_data = []\n",
    "    for img in os.listdir(DIR):\n",
    "        label = label_img(img)\n",
    "        if label is None:\n",
    "            continue\n",
    "        path = os.path.join(DIR, img)\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('L')\n",
    "        img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "        train_data.append([np.array(img), label])\n",
    "        \n",
    "        # Basic Data Augmentation - Horizontal Flipping\n",
    "        flip_img = Image.open(path)\n",
    "        flip_img = flip_img.convert('L') # L means grayscale\n",
    "        flip_img = flip_img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "        flip_img = np.array(flip_img)\n",
    "        flip_img = np.fliplr(flip_img)\n",
    "        train_data.append([flip_img, label])\n",
    "        \n",
    "    shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data[43][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cross validation set\n",
    "cv_data = train_data[-100:]\n",
    "train_data = train_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_data])\n",
    "cvImages = np.array([i[0] for i in cv_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "cvLabels = np.array([i[1] for i in cv_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 1.2038 - acc: 0.4900\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.2622 - acc: 0.9200\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.1286 - acc: 0.9700\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0671 - acc: 0.9800\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 0.0547 - acc: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b596d6908>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainImages, trainLabels, batch_size =  50, epochs = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(cvImages, cvLabels, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10222"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 300, 300, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainImages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py]",
   "language": "python",
   "name": "conda-env-py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
